{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6 Lab Session: Classification in NLTK\n",
    "Classify Sentiment given document\n",
    "Week 7 Â· Discourse and Dialogue\n",
    "\n",
    "In this exercise we try different feature vector sizes and compare accuracy of models from each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique count of all words in documents: 39768\n"
     ]
    }
   ],
   "source": [
    "### classify documents based on keywords\n",
    "from nltk.corpus import movie_reviews\n",
    "import nltk\n",
    "import random\n",
    "# for each document in movie_reviews, get its words and category (positive/negative)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "## use words from all documents to define the word vector for features\n",
    "# get all words from all movie_reviews and put into a frequency distribution\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "print(\"Unique count of all words in documents: {:d}\".format(len(all_words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features (keywords) of a document\n",
    "# each feature is 'contains(keyword)' and is true or false depending\n",
    "# on whether that keyword is in the document\n",
    "def document_features(document, word_features):\n",
    "\tdocument_words = set(document)\n",
    "\tfeatures = {}\n",
    "\tfor word in word_features:\n",
    "\t\tfeatures['V_%s' % word] = (word in document_words)\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Features: Top 2000 Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of fv_size = 2000: 0.79\n"
     ]
    }
   ],
   "source": [
    "# get the 2000 most frequently appearing keywords in the corpus\n",
    "n = 2000\n",
    "word_items = all_words.most_common(n)\n",
    "word_features = [word for (word, freq) in word_items]\n",
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in documents]\n",
    "# training using naive Baysian classifier with a 95/5 split\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "# evaluate the accuracy of the classifier\n",
    "print (\"\\nAccuracy of fv_size = {:d}: {:.2f}\".format(n,  nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features: Top 3000 Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of fv_size = 3000: 0.79\n"
     ]
    }
   ],
   "source": [
    "# get the 3000 most frequently appearing keywords in the corpus\n",
    "n = 3000\n",
    "word_items = all_words.most_common(n)\n",
    "word_features = [word for (word, freq) in word_items]\n",
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in documents]\n",
    "# training using naive Baysian classifier with a 95/5 split\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "# evaluate the accuracy of the classifier\n",
    "print (\"\\nAccuracy of fv_size = {:d}: {:.2f}\".format(n,  nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features: Top 1000 Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of fv_size = 1000: 0.77\n"
     ]
    }
   ],
   "source": [
    "# get the 1000 most frequently appearing keywords in the corpus\n",
    "n = 1000\n",
    "word_items = all_words.most_common(n)\n",
    "word_features = [word for (word, freq) in word_items]\n",
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in documents]\n",
    "# training using naive Baysian classifier with a 95/5 split\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "# evaluate the accuracy of the classifier\n",
    "print (\"\\nAccuracy of fv_size = {:d}: {:.2f}\".format(n,  nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features: Top 4000 Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of fv_size = 4000: 0.81\n"
     ]
    }
   ],
   "source": [
    "# get the 4000 most frequently appearing keywords in the corpus\n",
    "n = 4000\n",
    "word_items = all_words.most_common(n)\n",
    "word_features = [word for (word, freq) in word_items]\n",
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in documents]\n",
    "# training using naive Baysian classifier with a 95/5 split\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "# evaluate the accuracy of the classifier\n",
    "print (\"\\nAccuracy of fv_size = {:d}: {:.2f}\".format(n,  nltk.classify.accuracy(classifier, test_set)))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python36564bitbasecondacd90c988128e4e428ceb9fe9a1123e59"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
