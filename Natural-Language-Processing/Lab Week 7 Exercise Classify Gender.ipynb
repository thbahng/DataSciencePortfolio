{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6 Lab Session: Classification in NLTK\n",
    "Classify Gender given Name\n",
    "Week 7 Â· Discourse and Dialogue\n",
    "\n",
    "In this exercise we try different feature extraction functions and compare accuracy of models from each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_letter': 'k'}\n",
      "{'suffix1': 'k', 'suffix2': 'e'}\n",
      "{'suffix1': 'e', 'suffix2': 'h', 'suffix3': 's'}\n"
     ]
    }
   ],
   "source": [
    "# define a feature extraction function for each name\n",
    "# this function prints the last letter of a word\n",
    "def gender_features1(word):\n",
    "    return{'last_letter': word[-1]}\n",
    "print(gender_features('Shrek'))\n",
    "\n",
    "# this function prints the last 1 and 2 letters of a word\n",
    "def gender_features2(word):\n",
    "    return{'suffix1': word[-1], 'suffix2':word[-2]}\n",
    "print(gender_features2('Shrek'))\n",
    "\n",
    "# this function prints the last 1, 2 and 3 letters of a word\n",
    "def gender_features3(word):\n",
    "    return{'suffix1': word[-1], 'suffix2':word[-2], 'suffix3':word[0]}\n",
    "print(gender_features3('she'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get male and female first names from nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim', 'Abdullah', 'Abe', 'Abel', 'Abelard', 'Abner', 'Abraham', 'Abram', 'Ace', 'Adair', 'Adam']\n",
      "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale', 'Abra', 'Acacia', 'Ada', 'Adah', 'Adaline', 'Adara', 'Addie', 'Addis', 'Adel', 'Adela']\n"
     ]
    }
   ],
   "source": [
    "# resource for male and female first names\n",
    "from nltk.corpus import names\n",
    "print(names.words('male.txt')[:20])\n",
    "print(names.words('female.txt')[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a master list of tuples of the name and the respective gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of male and female names paired with gender\n",
    "namesgender = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "          [(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the list items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gigi', 'female'), ('Jennings', 'male'), ('Angil', 'female'), ('Aprilette', 'female'), ('Hakeem', 'male'), ('Wileen', 'female'), ('Valera', 'female'), ('Jermaine', 'female'), ('Sebastien', 'male'), ('Phoebe', 'female'), ('Marcella', 'female'), ('Estella', 'female'), ('Templeton', 'male'), ('Cynthia', 'female'), ('Vincent', 'male'), ('Geralda', 'female'), ('Kalinda', 'female'), ('Devonne', 'female'), ('Srinivas', 'male'), ('Francis', 'male')]\n"
     ]
    }
   ],
   "source": [
    "# put the list into random order\n",
    "import random\n",
    "random.shuffle(namesgender)\n",
    "print(namesgender[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the names into training and test\n",
    "train_names = namesgender[500:]\n",
    "test_names = namesgender[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'last_letter': 'e'}, 'female'), ({'last_letter': 'l'}, 'female'), ({'last_letter': 'y'}, 'female'), ({'last_letter': 'u'}, 'male'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'l'}, 'female'), ({'last_letter': 'l'}, 'male'), ({'last_letter': 'e'}, 'male'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 'e'}, 'male'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'i'}, 'female'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 's'}, 'male'), ({'last_letter': 'y'}, 'female'), ({'last_letter': 'd'}, 'male')]\n"
     ]
    }
   ],
   "source": [
    "# use our features to train a classification model and test on the development test set\n",
    "train_set = [(gender_features1(n), g) for (n, g) in train_names]\n",
    "test_set = [(gender_features1(n), g) for (n, g) in test_names]\n",
    "print(train_set[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n"
     ]
    }
   ],
   "source": [
    "# classify accuracy function runs the classifier on the test set and reports\n",
    "#   comparisons between predicted labels and actual/gold labels\n",
    "print(nltk.classify.accuracy(classifier1, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# use our features to train a classification model and test on the development test set\n",
    "train_set = [(gender_features2(n), g) for (n, g) in train_names]\n",
    "test_set = [(gender_features2(n), g) for (n, g) in test_names]\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier2, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features3(n), g) for (n, g) in train_names]\n",
    "test_set = [(gender_features3(n), g) for (n, g) in test_names]\n",
    "classifier3 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier3, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 104 errors with model 1 (see sample):\n",
      "\n",
      "[('female', 'male', 'Angil'), ('female', 'male', 'Wileen'), ('male', 'female', 'Terrence'), ('female', 'male', 'Chris'), ('male', 'female', 'Prince'), ('female', 'male', 'Charis'), ('female', 'male', 'Donnajean'), ('male', 'female', 'Osbourne'), ('male', 'female', 'Neddie'), ('female', 'male', 'Nariko')]\n"
     ]
    }
   ],
   "source": [
    "# define a function that will compare the classifier labels with the gold standard labels\n",
    "def geterrors(test):\n",
    "    errors = []\n",
    "    for (name, tag) in test:\n",
    "        guess = classifier1.classify(gender_features1(name))\n",
    "        if guess != tag:\n",
    "            errors.append( (tag, guess, name) )\n",
    "    return errors\n",
    "\n",
    "errors = geterrors(test_names)\n",
    "print(\"There are {:d} errors with model 1 (see sample):\\n\".format(len(errors)))\n",
    "print(errors[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 errors with model 2 (see sample):\n",
      "\n",
      "[('female', 'male', 'Wileen'), ('male', 'female', 'Vincent'), ('male', 'female', 'Kent'), ('male', 'female', 'Terrence'), ('female', 'male', 'Chris'), ('male', 'female', 'Prince'), ('female', 'male', 'Charis'), ('female', 'male', 'Stacy'), ('female', 'male', 'Donnajean'), ('male', 'female', 'Osbourne')]\n"
     ]
    }
   ],
   "source": [
    "# define a function that will compare the classifier labels with the gold standard labels\n",
    "def geterrors(test):\n",
    "    errors = []\n",
    "    for (name, tag) in test:\n",
    "        guess = classifier2.classify(gender_features2(name))\n",
    "        if guess != tag:\n",
    "            errors.append( (tag, guess, name) )\n",
    "    return errors\n",
    "\n",
    "errors = geterrors(test_names)\n",
    "print(\"There are {:d} errors with model 2 (see sample):\\n\".format(len(errors)))\n",
    "print(errors[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 97 errors with model 3 (see sample):\n",
      "\n",
      "[('female', 'male', 'Wileen'), ('male', 'female', 'Vincent'), ('male', 'female', 'Kent'), ('male', 'female', 'Terrence'), ('female', 'male', 'Chris'), ('male', 'female', 'Prince'), ('female', 'male', 'Charis'), ('female', 'male', 'Stacy'), ('female', 'male', 'Donnajean'), ('male', 'female', 'Osbourne')]\n"
     ]
    }
   ],
   "source": [
    "# define a function that will compare the classifier labels with the gold standard labels\n",
    "def geterrors(test):\n",
    "    errors = []\n",
    "    for (name, tag) in test:\n",
    "        guess = classifier3.classify(gender_features3(name))\n",
    "        if guess != tag:\n",
    "            errors.append( (tag, guess, name) )\n",
    "    return errors\n",
    "\n",
    "errors = geterrors(test_names)\n",
    "print(\"There are {:d} errors with model 3 (see sample):\\n\".format(len(errors)))\n",
    "print(errors[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python36564bitbasecondacd90c988128e4e428ceb9fe9a1123e59"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
