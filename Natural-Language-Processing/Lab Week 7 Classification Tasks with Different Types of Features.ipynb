{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Week 7 Classification Tasks\n",
    "With Different types of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classify Gender given Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'last_letter': 'k'}\n"
     ]
    }
   ],
   "source": [
    "# define a feature extraction function for each name\n",
    "# this function prints the last letter of a word\n",
    "def gender_features(word):\n",
    "    return{'last_letter': word[-1]}\n",
    "print(gender_features('Shrek'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A List of Male and Female names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get male and female first names from nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim', 'Abdullah', 'Abe', 'Abel', 'Abelard', 'Abner', 'Abraham', 'Abram', 'Ace', 'Adair', 'Adam']\n",
      "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale', 'Abra', 'Acacia', 'Ada', 'Adah', 'Adaline', 'Adara', 'Addie', 'Addis', 'Adel', 'Adela']\n"
     ]
    }
   ],
   "source": [
    "# resource for male and female first names\n",
    "from nltk.corpus import names\n",
    "print(names.words('male.txt')[:20])\n",
    "print(names.words('female.txt')[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a master list of tuples of the name and the respective gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7944\n",
      "[('Aamir', 'male'), ('Aaron', 'male'), ('Abbey', 'male'), ('Abbie', 'male'), ('Abbot', 'male'), ('Abbott', 'male'), ('Abby', 'male'), ('Abdel', 'male'), ('Abdul', 'male'), ('Abdulkarim', 'male'), ('Abdullah', 'male'), ('Abe', 'male'), ('Abel', 'male'), ('Abelard', 'male'), ('Abner', 'male'), ('Abraham', 'male'), ('Abram', 'male'), ('Ace', 'male'), ('Adair', 'male'), ('Adam', 'male')]\n",
      "[('Zena', 'female'), ('Zenia', 'female'), ('Zia', 'female'), ('Zilvia', 'female'), ('Zita', 'female'), ('Zitella', 'female'), ('Zoe', 'female'), ('Zola', 'female'), ('Zonda', 'female'), ('Zondra', 'female'), ('Zonnya', 'female'), ('Zora', 'female'), ('Zorah', 'female'), ('Zorana', 'female'), ('Zorina', 'female'), ('Zorine', 'female'), ('Zsa Zsa', 'female'), ('Zsazsa', 'female'), ('Zulema', 'female'), ('Zuzana', 'female')]\n"
     ]
    }
   ],
   "source": [
    "# make list of male and female names paired with gender\n",
    "namesgender = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "          [(name, 'female') for name in names.words('female.txt')])\n",
    "print(len(namesgender))\n",
    "print(namesgender[:20])\n",
    "print(namesgender[7924:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the list items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Somerset', 'male'), ('Emmott', 'male'), ('Neal', 'male'), ('Leena', 'female'), ('Masha', 'female'), ('Tricia', 'female'), ('Maribel', 'female'), ('Cilka', 'female'), ('Aubrette', 'female'), ('Genna', 'female'), ('Patrice', 'female'), ('Caty', 'female'), ('Rebe', 'female'), ('Maris', 'female'), ('Roy', 'male'), ('Kissiah', 'female'), ('Merrielle', 'female'), ('Veronike', 'female'), ('Dabney', 'male'), ('Stephie', 'female')]\n"
     ]
    }
   ],
   "source": [
    "# put the list into random order\n",
    "import random\n",
    "random.shuffle(namesgender)\n",
    "print(namesgender[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 94% : 6% train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the names into training and test\n",
    "train_names = namesgender[500:]\n",
    "test_names = namesgender[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'last_letter': 'e'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 'y'}, 'male'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'n'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 't'}, 'female'), ({'last_letter': 'e'}, 'female'), ({'last_letter': 'i'}, 'female'), ({'last_letter': 'h'}, 'male'), ({'last_letter': 'e'}, 'male'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'n'}, 'female'), ({'last_letter': 'a'}, 'female'), ({'last_letter': 'e'}, 'male'), ({'last_letter': 'y'}, 'male')]\n"
     ]
    }
   ],
   "source": [
    "# use our features to train a classification model and test on the development test set\n",
    "train_set = [(gender_features(n), g) for (n, g) in train_names]\n",
    "test_set = [(gender_features(n), g) for (n, g) in test_names]\n",
    "print(train_set[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Naive Bayes Classification Model from a training set\n",
    "### The training set contains the last letters of names and respective gender label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a couple names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "# classify new instances\n",
    "print(classifier.classify(gender_features('Neo')))\n",
    "print(classifier.classify(gender_features('Trinity')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test set and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "# classify accuracy function runs the classifier on the test set and reports\n",
    "#   comparisons between predicted labels and actual/gold labels\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     35.8 : 1.0\n",
      "             last_letter = 'k'              male : female =     33.0 : 1.0\n",
      "             last_letter = 'f'              male : female =     17.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.1 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.1 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.4 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.3 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.3 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.4 : 1.0\n",
      "             last_letter = 'g'              male : female =      4.7 : 1.0\n",
      "             last_letter = 'b'              male : female =      4.3 : 1.0\n",
      "             last_letter = 's'              male : female =      4.3 : 1.0\n",
      "             last_letter = 'w'              male : female =      4.1 : 1.0\n",
      "             last_letter = 'j'              male : female =      3.9 : 1.0\n",
      "             last_letter = 't'              male : female =      3.8 : 1.0\n",
      "             last_letter = 'i'            female : male   =      3.8 : 1.0\n",
      "             last_letter = 'z'              male : female =      3.6 : 1.0\n",
      "             last_letter = 'u'              male : female =      2.6 : 1.0\n",
      "             last_letter = 'n'              male : female =      2.1 : 1.0\n",
      "             last_letter = 'l'              male : female =      1.8 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# this function available for naive bayes classifiers\n",
    "print(classifier.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the classifier labels with the gold standard labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "# define a function that will compare the classifier labels with the gold standard labels\n",
    "def geterrors(test):\n",
    "    errors = []\n",
    "    for (name, tag) in test:\n",
    "        guess = classifier.classify(gender_features(name))\n",
    "        if guess != tag:\n",
    "            errors.append( (tag, guess, name) )\n",
    "    return errors\n",
    "\n",
    "errors = geterrors(test_names)\n",
    "print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Alisun                        \n",
      "correct=female   guess=male     name=Allison                       \n",
      "correct=female   guess=male     name=Ardelis                       \n",
      "correct=female   guess=male     name=Arlyn                         \n",
      "correct=female   guess=male     name=Bel                           \n",
      "correct=female   guess=male     name=Bird                          \n",
      "correct=female   guess=male     name=Camel                         \n",
      "correct=female   guess=male     name=Charmion                      \n",
      "correct=female   guess=male     name=Chris                         \n",
      "correct=female   guess=male     name=Cristabel                     \n",
      "correct=female   guess=male     name=Cyb                           \n",
      "correct=female   guess=male     name=Dido                          \n",
      "correct=female   guess=male     name=Eileen                        \n",
      "correct=female   guess=male     name=Eran                          \n",
      "correct=female   guess=male     name=Ethyl                         \n",
      "correct=female   guess=male     name=Evangelin                     \n",
      "correct=female   guess=male     name=Faun                          \n",
      "correct=female   guess=male     name=Fran                          \n",
      "correct=female   guess=male     name=Gus                           \n",
      "correct=female   guess=male     name=Isobel                        \n",
      "correct=female   guess=male     name=Jaynell                       \n",
      "correct=female   guess=male     name=Jenifer                       \n",
      "correct=female   guess=male     name=Jewel                         \n",
      "correct=female   guess=male     name=Jocelyn                       \n",
      "correct=female   guess=male     name=Jourdan                       \n",
      "correct=female   guess=male     name=Karel                         \n",
      "correct=female   guess=male     name=Kass                          \n",
      "correct=female   guess=male     name=Kellen                        \n",
      "correct=female   guess=male     name=Kellyann                      \n",
      "correct=female   guess=male     name=Koren                         \n",
      "correct=female   guess=male     name=Linet                         \n",
      "correct=female   guess=male     name=Lorain                        \n",
      "correct=female   guess=male     name=Maribel                       \n",
      "correct=female   guess=male     name=Marie-Ann                     \n",
      "correct=female   guess=male     name=Marillin                      \n",
      "correct=female   guess=male     name=Marin                         \n",
      "correct=female   guess=male     name=Maris                         \n",
      "correct=female   guess=male     name=Nadean                        \n",
      "correct=female   guess=male     name=Nichol                        \n",
      "correct=female   guess=male     name=Nicol                         \n",
      "correct=female   guess=male     name=Norean                        \n",
      "correct=female   guess=male     name=Pru                           \n",
      "correct=female   guess=male     name=Rahal                         \n",
      "correct=female   guess=male     name=Ros                           \n",
      "correct=female   guess=male     name=Shel                          \n",
      "correct=female   guess=male     name=Shell                         \n",
      "correct=female   guess=male     name=Tess                          \n",
      "correct=female   guess=male     name=Theo                          \n",
      "correct=male     guess=female   name=Aldrich                       \n",
      "correct=male     guess=female   name=Anthony                       \n",
      "correct=male     guess=female   name=Antoni                        \n",
      "correct=male     guess=female   name=Archie                        \n",
      "correct=male     guess=female   name=Ari                           \n",
      "correct=male     guess=female   name=Brooke                        \n",
      "correct=male     guess=female   name=Chauncey                      \n",
      "correct=male     guess=female   name=Clarke                        \n",
      "correct=male     guess=female   name=Dabney                        \n",
      "correct=male     guess=female   name=Dane                          \n",
      "correct=male     guess=female   name=Danny                         \n",
      "correct=male     guess=female   name=Dimitry                       \n",
      "correct=male     guess=female   name=Ellsworth                     \n",
      "correct=male     guess=female   name=Emmy                          \n",
      "correct=male     guess=female   name=Geoffrey                      \n",
      "correct=male     guess=female   name=Geoffry                       \n",
      "correct=male     guess=female   name=George                        \n",
      "correct=male     guess=female   name=Georgy                        \n",
      "correct=male     guess=female   name=Godfry                        \n",
      "correct=male     guess=female   name=Grace                         \n",
      "correct=male     guess=female   name=Guthrey                       \n",
      "correct=male     guess=female   name=Hartley                       \n",
      "correct=male     guess=female   name=Harvie                        \n",
      "correct=male     guess=female   name=Hewie                         \n",
      "correct=male     guess=female   name=Hymie                         \n",
      "correct=male     guess=female   name=Jamie                         \n",
      "correct=male     guess=female   name=Jedediah                      \n",
      "correct=male     guess=female   name=Jermayne                      \n",
      "correct=male     guess=female   name=Kirby                         \n",
      "correct=male     guess=female   name=Klee                          \n",
      "correct=male     guess=female   name=Krishna                       \n",
      "correct=male     guess=female   name=Lawerence                     \n",
      "correct=male     guess=female   name=Lay                           \n",
      "correct=male     guess=female   name=Lefty                         \n",
      "correct=male     guess=female   name=Lenny                         \n",
      "correct=male     guess=female   name=Lex                           \n",
      "correct=male     guess=female   name=Luce                          \n",
      "correct=male     guess=female   name=Moise                         \n",
      "correct=male     guess=female   name=Monroe                        \n",
      "correct=male     guess=female   name=Montague                      \n",
      "correct=male     guess=female   name=Mugsy                         \n",
      "correct=male     guess=female   name=Munroe                        \n",
      "correct=male     guess=female   name=Murray                        \n",
      "correct=male     guess=female   name=Myke                          \n",
      "correct=male     guess=female   name=Partha                        \n",
      "correct=male     guess=female   name=Pembroke                      \n",
      "correct=male     guess=female   name=Pierre                        \n",
      "correct=male     guess=female   name=Prentice                      \n",
      "correct=male     guess=female   name=Reece                         \n",
      "correct=male     guess=female   name=Ricky                         \n",
      "correct=male     guess=female   name=Roth                          \n",
      "correct=male     guess=female   name=Roy                           \n",
      "correct=male     guess=female   name=Rutledge                      \n",
      "correct=male     guess=female   name=Shane                         \n",
      "correct=male     guess=female   name=Si                            \n",
      "correct=male     guess=female   name=Tabby                         \n",
      "correct=male     guess=female   name=Torre                         \n",
      "correct=male     guess=female   name=Tre                           \n",
      "correct=male     guess=female   name=Tremayne                      \n",
      "correct=male     guess=female   name=Vasily                        \n",
      "correct=male     guess=female   name=Wally                         \n",
      "correct=male     guess=female   name=Wiley                         \n"
     ]
    }
   ],
   "source": [
    "# define a function to print the errors\n",
    "def printerrors(errors):\n",
    "    for (tag, guess, name) in sorted(errors):\n",
    "        print('correct={:<8s} guess={:<8s} name={:<30s}'.format(tag, guess, name))\n",
    "\n",
    "printerrors(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# define features for the \"i\"th word in the sentence, including three types of suffix \n",
    "#     and one pre-word\n",
    "# the pos features function takes the sentence of untagged words and the index of a word i\n",
    "#   it creates features for word i, including the previous word i-1\n",
    "def pos_features(sentence, i):    \n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "\t\t    \"suffix(2)\": sentence[i][-2:],\n",
    "\t\t    \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect features of a specific word in a specific sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "investigation\n"
     ]
    }
   ],
   "source": [
    "# look at features of a specific word in a specific sentence\n",
    "# first sentence of brown corpus\n",
    "sentence0 = brown.sents()[0]\n",
    "print(sentence0)\n",
    "# word 8 of sentence 0\n",
    "print(sentence0[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech features of the specific word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion', 'prev-word': 'an'}\n"
     ]
    }
   ],
   "source": [
    "# pos features of word 8 \n",
    "print(pos_features(sentence0, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagged sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# get the POS tagged sentences with categories of news\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "tag_sent0 = tagged_sents[0]\n",
    "print(tag_sent0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to untag a POS tagged sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "source": [
    "# the function nltk.tag.untag will take the tags off\n",
    "print(nltk.tag.untag(tag_sent0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The AT\n",
      "1 Fulton NP-TL\n",
      "2 County NN-TL\n",
      "3 Grand JJ-TL\n",
      "4 Jury NN-TL\n",
      "5 said VBD\n",
      "6 Friday NR\n",
      "7 an AT\n",
      "8 investigation NN\n",
      "9 of IN\n",
      "10 Atlanta's NP$\n",
      "11 recent JJ\n",
      "12 primary NN\n",
      "13 election NN\n",
      "14 produced VBD\n",
      "15 `` ``\n",
      "16 no AT\n",
      "17 evidence NN\n",
      "18 '' ''\n",
      "19 that CS\n",
      "20 any DTI\n",
      "21 irregularities NNS\n",
      "22 took VBD\n",
      "23 place NN\n",
      "24 . .\n"
     ]
    }
   ],
   "source": [
    "# the python enumerate function generates an index number for each item in a list\n",
    "for i,(word,tag) in enumerate(tag_sent0):\n",
    "    print (i, word, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature sets\n",
    "### These are words appearing in the corpus, from untagged sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100554 featuresets.\n"
     ]
    }
   ],
   "source": [
    "# get feature sets of words appearing in the corpus, from untagged sentences.\n",
    "# and then get their tags from corresponding tagged sentence\n",
    "# use the Python function enumerate to pair the index numbers with sentence words \n",
    "#   for the pos features function\n",
    "featuresets = []\n",
    "for tagged_sent in tagged_sents:\n",
    "\tuntagged_sent = nltk.tag.untag(tagged_sent)\n",
    "\tfor i, (word, tag) in enumerate(tagged_sent):\n",
    "\t\tfeaturesets.append( (pos_features(untagged_sent, i), tag) )\n",
    "\n",
    "print(\"There are {:d} featuresets.\".format(len(featuresets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the feature sets of the first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'suffix(1)': 'e', 'suffix(2)': 'he', 'suffix(3)': 'The', 'prev-word': '<START>'}, 'AT')\n",
      "({'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ton', 'prev-word': 'The'}, 'NP-TL')\n",
      "({'suffix(1)': 'y', 'suffix(2)': 'ty', 'suffix(3)': 'nty', 'prev-word': 'Fulton'}, 'NN-TL')\n",
      "({'suffix(1)': 'd', 'suffix(2)': 'nd', 'suffix(3)': 'and', 'prev-word': 'County'}, 'JJ-TL')\n",
      "({'suffix(1)': 'y', 'suffix(2)': 'ry', 'suffix(3)': 'ury', 'prev-word': 'Grand'}, 'NN-TL')\n",
      "({'suffix(1)': 'd', 'suffix(2)': 'id', 'suffix(3)': 'aid', 'prev-word': 'Jury'}, 'VBD')\n",
      "({'suffix(1)': 'y', 'suffix(2)': 'ay', 'suffix(3)': 'day', 'prev-word': 'said'}, 'NR')\n",
      "({'suffix(1)': 'n', 'suffix(2)': 'an', 'suffix(3)': 'an', 'prev-word': 'Friday'}, 'AT')\n",
      "({'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion', 'prev-word': 'an'}, 'NN')\n",
      "({'suffix(1)': 'f', 'suffix(2)': 'of', 'suffix(3)': 'of', 'prev-word': 'investigation'}, 'IN')\n"
     ]
    }
   ],
   "source": [
    "# look at the feature sets of the first 10 words\n",
    "for f in featuresets[:10]:\n",
    "\tprint (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split of 90%/10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 90499 observations\n",
      "The test set has 10055 observations\n"
     ]
    }
   ],
   "source": [
    "# using naive Bayesian as classifier\n",
    "# split data into a training set and a test set, using a 90%/10% split\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "print(\"The training set has {:d} observations\".format(len(train_set)))\n",
    "print(\"The test set has {:d} observations\".format(len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Naive Bayes classifier on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the accuracy of model by predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7891596220785678\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy (this will take a little while)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "# the result is reasonable for features without the previous tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifying Documents Based on Keywords\n",
    "Objective: classify positive or negative labels given features about movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classify documents based on keywords\n",
    "from nltk.corpus import movie_reviews\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "# movie reviews are labeled either positive or negative (by human annotators)\n",
    "print(movie_reviews.categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of tokenized documents (movie reviews)\n",
    "### Each document is a tuple of a tokenized review and a pos/neg label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 documents\n"
     ]
    }
   ],
   "source": [
    "# for each document in movie_reviews, get its words and category (positive/negative)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "              for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n",
    "print(\"There are {:d} documents\".format(len(documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly Shuffle Documents / Inspect one of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['much', 'ado', 'about', 'nothing', '.', 'ah', ',', 'how', 'sweet', 'the', 'irony', '!', 'it', \"'\", 's', 'accepted', 'wisdom', 'in', 'some', 'circles', '-', 'among', 'english', 'literature', 'nuts', ',', 'mainly', '-', 'that', 'whenever', 'a', 'critic', 'knocks', 'shakespeare', 'they', 'are', 'only', 'doing', 'so', 'through', 'ignorance', '.', 'he', 'just', 'doesn', \"'\", 't', '\"', 'understand', '\"', 'shakespeare', ',', 'you', 'will', 'hear', 'them', 'say', '.', 'the', 'bard', \"'\", 's', 'work', 'is', 'apparently', 'beyond', 'criticism', '.', 'what', 'a', 'load', 'of', 'old', 'cobblers', '.', 'if', 'these', 'arbiters', 'of', 'public', 'taste', 'think', 'kenneth', 'branaugh', \"'\", 's', 'film', 'of', 'shakespeare', \"'\", 's', '\"', 'comedy', '\"', 'much', 'ado', 'about', 'nothing', 'is', 'comedy', 'in', 'any', 'modern', 'sense', 'of', 'the', 'word', ',', 'it', \"'\", 's', 'time', 'to', 'get', 'a', 'life', '.', 'get', 'monty', 'python', '.', 'get', 'woody', 'allen', '.', 'get', 'john', 'waters', '.', 'whatever', '.', 'just', 'get', 'a', 'real', 'taste', 'of', 'some', 'clever', ',', 'witty', ',', 'risky', 'comedy', '.', 'and', 'banish', 'this', 'nonsense', 'to', 'where', 'it', 'belongs', '.', 'drama', 'and', 'tragedy', 'was', 'shakespeare', \"'\", 's', 'strength', '.', 'to', 'my', 'sensibilities', '-', 'and', 'i', \"'\", 'm', 'no', 'stick', 'in', 'the', 'mud', '-', 'much', 'ado', 'about', 'nothing', 'resonates', 'with', 'no', 'spark', 'whatsoever', '.', 'no', 'kidding', ':', 'this', 'film', 'ranks', 'among', 'the', 'most', 'embarrassing', 'two', 'hours', 'i', 'have', 'ever', 'spent', 'in', 'a', 'cinema', 'in', 'my', '20', 'years', 'of', 'movie', 'going', '.', 'the', 'only', 'thing', 'that', 'stopped', 'me', 'walking', 'out', 'was', 'loyalty', 'to', 'my', 'lady', 'friend', ',', 'as', 'this', 'was', 'our', 'day', 'out', 'and', 'i', 'hadn', \"'\", 't', 'seen', 'her', 'in', 'ages', '.', 'but', 'boy', ',', 'does', 'she', 'owe', 'me', 'one', '!', 'i', 'won', \"'\", 't', 'spend', 'too', 'much', 'time', 'on', 'the', 'plot', '.', 'basically', ',', 'we', 'follow', 'the', 'trials', 'and', 'tribulations', 'of', 'two', 'would', '-', 'be', 'couples', '-', 'one', 'young', ',', 'the', 'other', 'older', '.', 'there', \"'\", 's', 'some', 'dark', 'treachery', 'amongst', 'all', 'this', ',', 'but', 'everyone', 'is', 'so', 'awfully', 'jolly', 'that', 'you', \"'\", 'd', 'hardly', 'know', 'it', '.', 'mind', 'you', ',', 'there', \"'\", 's', 'nothing', 'wrong', 'with', 'the', 'basic', 'story', '.', 'good', 'romantic', 'comedies', 'based', 'on', 'similar', 'premises', 'abound', '.', 'nothing', 'wrong', 'with', 'most', 'of', 'the', 'cast', ',', 'either', '.', 'branaugh', ',', 'emma', 'thompson', 'and', 'denzel', 'washington', 'are', 'all', 'talented', 'performers', '.', 'the', 'problem', 'is', 'the', 'script', ',', 'or', 'more', 'accurately', ',', 'shakespeare', \"'\", 's', 'original', 'text', '.', 'light', 'comedy', 'shouldn', \"'\", 't', 'be', 'complex', '.', 'yet', 'wrapped', 'in', 'elizabethan', 'english', ',', 'the', 'dialogue', 'becomes', 'difficult', 'to', 'comprehend', '.', 'for', 'this', 'alone', 'it', 'will', 'be', 'a', 'problem', 'for', 'modern', 'audiences', 'unschooled', 'in', 'shakespeare', 'and', 'in', 'search', 'of', 'nothing', 'more', 'than', 'a', 'good', ',', 'undemanding', 'laugh', '.', 'the', 'only', 'laughs', 'to', 'escape', 'my', 'belly', 'were', 'brought', 'on', 'by', 'the', 'gloriously', 'inept', 'performance', 'of', 'keanu', 'reeves', ',', 'the', 'actor', 'once', 'again', 'miscast', 'as', 'a', 'jealous', 'half', '-', 'brother', 'or', 'something', '.', 'but', 'when', 'dissected', 'and', 'understood', ',', 'what', 'it', 'all', 'boils', 'down', 'to', 'is', 'that', 'this', 'stuff', 'is', 'just', 'so', 'goddamn', 'lame', '.', 'this', 'is', 'comedy', 'so', 'clean', 'and', 'nice', 'and', 'corny', 'and', 'so', 'devoid', 'of', 'danger', 'that', 'it', 'leaves', 'this', 'viewer', 'totally', 'cold', '.', 'ho', ',', 'ho', ',', 'ho', ',', 'boy', 'likes', 'girl', '!', 'ho', ',', 'ho', ',', 'ho', ',', 'men', 'are', 'such', 'klutzes', '!', 'ho', ',', 'ho', ',', 'ho', ',', 'she', \"'\", 's', 'so', 'awfully', 'clumsy', '!', 'oh', 'please', '!', 'there', \"'\", 's', 'wit', 'in', 'here', 'somewhere', ',', 'i', \"'\", 'm', 'told', '.', 'i', 'call', 'it', 'pretentious', '.', 'something', 'lightweight', 'striving', 'to', 'be', 'something', 'sophisticated', 'through', 'clever', 'wordplay', '.', 'in', 'the', 'end', ',', 'it', \"'\", 's', 'cringeworthy', '.', 'watching', 'some', 'of', 'the', 'cinema', 'patrons', 'around', 'me', 'collapse', 'with', 'laughter', 'made', 'much', 'ado', 'about', 'nothing', 'a', 'very', 'weird', 'movie', 'going', 'experience', '.', 'comedy', '?', 'bah', ',', 'humbug', '!'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(documents)\n",
    "# look at the first document - consists of a list of all the words in the review\n",
    "# followed by the category\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define word vector for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique count of all words in documents: 39768\n"
     ]
    }
   ],
   "source": [
    "## use words from all documents to define the word vector for features\n",
    "# get all words from all movie_reviews and put into a frequency distribution\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "print(\"Unique count of all words in documents: {:d}\".format(len(all_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the 2000 most frequently appearing keywords as our word features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'a', 'and', 'of', 'to', \"'\", 'is', 'in', 's', '\"', 'it', 'that', '-', ')', '(', 'as', 'with', 'for', 'his', 'this', 'film', 'i', 'he', 'but', 'on', 'are', 't', 'by', 'be', 'one', 'movie', 'an', 'who', 'not', 'you', 'from', 'at', 'was', 'have', 'they', 'has', 'her', 'all', '?', 'there', 'like', 'so', 'out', 'about', 'up', 'more', 'what', 'when', 'which', 'or', 'she', 'their', ':', 'some', 'just', 'can', 'if', 'we', 'him', 'into', 'even', 'only', 'than', 'no', 'good', 'time', 'most', 'its', 'will', 'story', 'would', 'been', 'much', 'character', 'also', 'get', 'other', 'do', 'two', 'well', 'them', 'very', 'characters', ';', 'first', '--', 'after', 'see', '!', 'way', 'because', 'make', 'life']\n"
     ]
    }
   ],
   "source": [
    "# get the 2000 most frequently appearing keywords in the corpus\n",
    "word_items = all_words.most_common(2000)\n",
    "word_features = [word for (word, freq) in word_items]   # just the words\n",
    "# look at the first 100 words\n",
    "print(word_features[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Feature Sets for all documents\n",
    "### Includes keyword features and category feature\n",
    "### Each feature set is a tuple comprised of a dictionary of key terms and boolean values for whether or not they are in the document, and an overall pos/neg label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 feature sets, one for each of the 2000 documents\n"
     ]
    }
   ],
   "source": [
    "# define features (keywords) of a document\n",
    "# each feature is 'contains(keyword)' and is true or false depending\n",
    "# on whether that keyword is in the document\n",
    "def document_features(document, word_features):\n",
    "\tdocument_words = set(document)\n",
    "\tfeatures = {}\n",
    "\tfor word in word_features:\n",
    "\t\tfeatures['V_%s' % word] = (word in document_words)\n",
    "\treturn features\n",
    "\n",
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d,c) in documents]    \n",
    "print(\"There are {:d} feature sets, one for each of the {:d} documents\".format(len(featuresets), len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature sets are 2000 words long - so this is optional\n",
    "#print(featuresets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split with a 95/5 split; Train Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training using naive Baysian classifier with a 95/5 split\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Accuracy of Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the classifier\n",
    "print (nltk.classify.accuracy(classifier, test_set))\n",
    "# the accuracy result may vary since we randomized the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           V_outstanding = True              pos : neg    =     10.3 : 1.0\n",
      "                 V_mulan = True              pos : neg    =      8.2 : 1.0\n",
      "                V_seagal = True              neg : pos    =      7.5 : 1.0\n",
      "           V_wonderfully = True              pos : neg    =      6.6 : 1.0\n",
      "                 V_flynt = True              pos : neg    =      5.6 : 1.0\n",
      "                 V_damon = True              pos : neg    =      5.6 : 1.0\n",
      "                 V_awful = True              neg : pos    =      5.4 : 1.0\n",
      "                  V_lame = True              neg : pos    =      5.3 : 1.0\n",
      "                V_wasted = True              neg : pos    =      5.2 : 1.0\n",
      "            V_ridiculous = True              neg : pos    =      5.2 : 1.0\n",
      "                V_poorly = True              neg : pos    =      5.1 : 1.0\n",
      "                 V_waste = True              neg : pos    =      4.8 : 1.0\n",
      "                   V_era = True              pos : neg    =      4.6 : 1.0\n",
      "                 V_bland = True              neg : pos    =      4.3 : 1.0\n",
      "                 V_worst = True              neg : pos    =      4.2 : 1.0\n",
      "               V_unfunny = True              neg : pos    =      4.1 : 1.0\n",
      "                  V_mess = True              neg : pos    =      4.0 : 1.0\n",
      "                V_allows = True              pos : neg    =      3.9 : 1.0\n",
      "             V_fantastic = True              pos : neg    =      3.9 : 1.0\n",
      "             V_pointless = True              neg : pos    =      3.9 : 1.0\n",
      "             V_laughable = True              neg : pos    =      3.9 : 1.0\n",
      "                V_stupid = True              neg : pos    =      3.9 : 1.0\n",
      "                  V_jedi = True              pos : neg    =      3.8 : 1.0\n",
      "              V_terrific = True              pos : neg    =      3.8 : 1.0\n",
      "             V_memorable = True              pos : neg    =      3.7 : 1.0\n",
      "             V_portrayal = True              pos : neg    =      3.6 : 1.0\n",
      "                  V_dull = True              neg : pos    =      3.6 : 1.0\n",
      "                 V_badly = True              neg : pos    =      3.5 : 1.0\n",
      "                V_boring = True              neg : pos    =      3.4 : 1.0\n",
      "              V_terrible = True              neg : pos    =      3.4 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# show which features of classifier are most informative\n",
    "print(classifier.show_most_informative_features(30))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python36564bitbasecondacd90c988128e4e428ceb9fe9a1123e59"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
