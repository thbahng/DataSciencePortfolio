{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "Week 2 - Corpus Statistics and Language Modeling\n",
    "\n",
    "Given a set of provided bigrams, compute the bigram predictive probabilites. (i.e. given bigram \"word1 word2\", the probability that word2 follows word1 in the corpus)\n",
    "For a bigram \"w1 w2\", P(w2|w1) = (count of \"w1 w2\") / (count of w1)\n",
    "\n",
    "Example:\n",
    "bigram = \"we bear\"\n",
    "count(\"we bear\") = 1\n",
    "count(\"we\") = 21\n",
    "P(\"we bear\") = 1/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk import word_tokenize\n",
    "from nltk import bigrams\n",
    "\n",
    "# function to convert raw input bigram into tuple\n",
    "# :param raw: a string representing a bigram (e.g. \"we will\")\n",
    "# :return: a tuple of split bigram (e.g. ('we', 'will'))\n",
    "def processDat(raw):\n",
    "    return tuple(raw.split())\n",
    "\n",
    "# function to compute predict probability for a bigram\n",
    "# requires frequency distribution of unigrams - \"fdist1\" and bigrams - \"fdist2\"\n",
    "# :param x: a tuple of split bigram (e.g. ('we', 'will'))\n",
    "# :return: prints fraction and decimal representing the bigram probability\n",
    "def getProb(x):\n",
    "    # string of bigram\n",
    "    myStr = ' '.join(x)\n",
    "    # frequency of bigram\n",
    "    a = fdist2[x]\n",
    "    # frequency of first word in bigram\n",
    "    b = fdist1[x[0]]\n",
    "    # probability string (fraction)\n",
    "    frac = str(a) + '/' + str(b)\n",
    "    # probability string (decimal)\n",
    "    dec = str(round(a/b, 3))\n",
    "    # print\n",
    "    print(\"Probability of '{:s}' is {:s} ({:s})\".format(myStr, frac, dec))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read local file\n",
    "f = open(\"data/sample_text1.txt\")\n",
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['each', 'time', 'we', 'gather', 'to', 'inaugurate', 'a', 'president', ',', 'we']\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text into unigrams; list of words\n",
    "tokens = word_tokenize(raw)\n",
    "# convert words to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 28), ('our', 23), ('we', 21), (',', 21), ('of', 18), ('.', 18), ('to', 17), ('and', 15), ('that', 14), ('a', 11)]\n"
     ]
    }
   ],
   "source": [
    "# get frequency distribution of unigrams\n",
    "fdist1 = FreqDist(tokens)\n",
    "# top 10 most common unigrams\n",
    "print(fdist1.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('.', 'we'), 10), (('of', 'our'), 6), (('is', 'not'), 5), (('we', 'will'), 4), (('.', 'our'), 4), (('our', 'journey'), 4), (('journey', 'is'), 4), (('not', 'complete'), 4), (('complete', 'until'), 4), ((',', 'that'), 3)]\n"
     ]
    }
   ],
   "source": [
    "# get bigrams from tokens\n",
    "bgrams = list(bigrams(tokens))\n",
    "# get frequency distribution of bigrams\n",
    "fdist2 = FreqDist(bgrams)\n",
    "# top 10 most common bigrams\n",
    "print(fdist2.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Compute Predictive Probabilities of Bigrams\n",
    "P(w2|w1) = (count of \"w1 w2\") / (count of w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram set A\n",
    "bgramA1 = processDat(\"we ,\")\n",
    "bgramA2 = processDat(\"we will\")\n",
    "bgramA3 = processDat(\"we know\")\n",
    "\n",
    "# Bigram set B\n",
    "bgramB1 = processDat(\"our people\")\n",
    "bgramB2 = processDat(\"our journey\")\n",
    "\n",
    "# Bigram set C\n",
    "bgramC1 = processDat(\"believe that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'we ,' is 3/21 (0.143)\n",
      "Probability of 'we will' is 4/21 (0.19)\n",
      "Probability of 'we know' is 1/21 (0.048)\n"
     ]
    }
   ],
   "source": [
    "# Compute bigram predictive probabilities for Bigram set A\n",
    "getProb(bgramA1)\n",
    "getProb(bgramA2)\n",
    "getProb(bgramA3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'our people' is 1/23 (0.043)\n",
      "Probability of 'our journey' is 4/23 (0.174)\n"
     ]
    }
   ],
   "source": [
    "# Compute bigram predictive probabilities for Bigram set B\n",
    "getProb(bgramB1)\n",
    "getProb(bgramB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'believe that' is 3/3 (1.0)\n"
     ]
    }
   ],
   "source": [
    "# Compute bigram predictive probabilities for Bigram set C\n",
    "getProb(bgramC1)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "2e67d2d51cc48135395e9785d6b518c9af6482520666ad00cf530c129701d75b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('Continuum': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
